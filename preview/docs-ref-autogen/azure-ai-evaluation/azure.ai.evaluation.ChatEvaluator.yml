### YamlMime:PythonClass
uid: azure.ai.evaluation.ChatEvaluator
name: ChatEvaluator
fullName: azure.ai.evaluation.ChatEvaluator
module: azure.ai.evaluation
inheritances:
- builtins.object
summary: "Initialize a chat evaluator configured for a specific Azure OpenAI model.\n\
  \n**Usage**\n\n<!-- literal_block {\"ids\": [], \"classes\": [], \"names\": [],\
  \ \"dupnames\": [], \"backrefs\": [], \"xml:space\": \"preserve\", \"force\": false,\
  \ \"language\": \"python\", \"highlight_args\": {}, \"linenos\": false} -->\n\n\
  ````python\n\n   chat_eval = ChatEvaluator(model_config)\n   conversation = [\n\
  \       {\"role\": \"user\", \"content\": \"What is the value of 2 + 2?\"},\n  \
  \     {\"role\": \"assistant\", \"content\": \"2 + 2 = 4\", \"context\": {\n   \
  \        \"citations\": [\n                   {\"id\": \"math_doc.md\", \"content\"\
  : \"Information about additions: 1 + 2 = 3, 2 + 2 = 4\"}\n               ]\n   \
  \        }\n       }\n   ]\n   result = chat_eval(conversation=conversation)\n \
  \  ````\n\n**Output format**\n\n<!-- literal_block {\"ids\": [], \"classes\": [],\
  \ \"names\": [], \"dupnames\": [], \"backrefs\": [], \"xml:space\": \"preserve\"\
  , \"force\": false, \"language\": \"python\", \"highlight_args\": {}, \"linenos\"\
  : false} -->\n\n````python\n\n   {\n       \"evaluation_per_turn\": {\n        \
  \   \"gpt_retrieval\": [1.0, 2.0],\n           \"gpt_groundedness\": [5.0, 2.0],\n\
  \           \"gpt_relevance\": [3.0, 5.0],\n           \"gpt_coherence\": [1.0,\
  \ 2.0],\n           \"gpt_fluency\": [3.0, 5.0]\n       }\n       \"gpt_retrieval\"\
  : 1.5,\n       \"gpt_groundedness\": 3.5,\n       \"gpt_relevance\": 4.0,\n    \
  \   \"gpt_coherence\": 1.5,\n       \"gpt_fluency\": 4.0\n   }\n   ````"
constructor:
  syntax: 'ChatEvaluator(model_config: dict, eval_last_turn: bool = False, parallel:
    bool = True)'
  parameters:
  - name: model_config
    description: Configuration for the Azure OpenAI model.
    isRequired: true
    types:
    - <xref:typing.Union>[<xref:azure.ai.evaluation.AzureOpenAIModelConfiguration>,
      <xref:azure.ai.evaluation.OpenAIModelConfiguration>]
  - name: eval_last_turn
    description: 'Set to True to evaluate only the most recent exchange in the dialogue,

      focusing on the latest user inquiry and the assistant''s corresponding response.
      Defaults to False'
    defaultValue: 'False'
    types:
    - <xref:bool>
  - name: parallel
    description: 'If True, use parallel execution for evaluators. Else, use sequential
      execution.

      Default is True.'
    defaultValue: 'True'
    types:
    - <xref:bool>
