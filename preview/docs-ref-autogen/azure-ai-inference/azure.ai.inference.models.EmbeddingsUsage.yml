### YamlMime:PythonClass
uid: azure.ai.inference.models.EmbeddingsUsage
name: EmbeddingsUsage
fullName: azure.ai.inference.models.EmbeddingsUsage
module: azure.ai.inference.models
inheritances:
- azure.ai.inference._model_base.Model
summary: 'Measurement of the amount of tokens used in this request and response.


  All required parameters must be populated in order to send to server.'
constructor:
  syntax: 'EmbeddingsUsage(*args: Any, **kwargs: Any)'
variables:
- description: Number of tokens in the request prompt. Required.
  name: input_tokens
  types:
  - <xref:int>
- description: 'Number of tokens used for the prompt sent to the AI model. Typically

    identical to `input_tokens`.

    However, certain AI models may add extra tokens to the input hence the number
    can be higher.

    (for example when input_type="query"). Required.'
  name: prompt_tokens
  types:
  - <xref:int>
- description: Total number of tokens transacted in this request/response. Required.
  name: total_tokens
  types:
  - <xref:int>
methods:
- uid: azure.ai.inference.models.EmbeddingsUsage.as_dict
  name: as_dict
  summary: Return a dict that can be JSONify using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.inference.models.EmbeddingsUsage.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.inference.models.EmbeddingsUsage.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.inference.models.EmbeddingsUsage.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.inference.models.EmbeddingsUsage.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.inference.models.EmbeddingsUsage.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.inference.models.EmbeddingsUsage.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.EmbeddingsUsage.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.inference.models.EmbeddingsUsage.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.EmbeddingsUsage.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.inference.models.EmbeddingsUsage.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.inference.models.EmbeddingsUsage.input_tokens
  name: input_tokens
  summary: Number of tokens in the request prompt. Required.
  signature: 'input_tokens: int'
- uid: azure.ai.inference.models.EmbeddingsUsage.prompt_tokens
  name: prompt_tokens
  summary: 'Number of tokens used for the prompt sent to the AI model. Typically identical
    to

    `input_tokens`.

    However, certain AI models may add extra tokens to the input hence the number
    can be higher.

    (for example when input_type="query"). Required.'
  signature: 'prompt_tokens: int'
- uid: azure.ai.inference.models.EmbeddingsUsage.total_tokens
  name: total_tokens
  summary: Total number of tokens transacted in this request/response. Required.
  signature: 'total_tokens: int'
