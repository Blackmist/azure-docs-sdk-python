### YamlMime:PythonClass
uid: azure.ai.projects.operations.InferenceOperations
name: InferenceOperations
fullName: azure.ai.projects.operations.InferenceOperations
module: azure.ai.projects.operations
inheritances:
- builtins.object
constructor:
  syntax: InferenceOperations(outer_instance)
  parameters:
  - name: outer_instance
    isRequired: true
methods:
- uid: azure.ai.projects.operations.InferenceOperations.get_azure_openai_client
  name: get_azure_openai_client
  summary: 'Get an authenticated AzureOpenAI client (from the *openai* package) for
    the default

    Azure OpenAI connection. The package *openai* must be installed prior to calling
    this method.

    Raises ~azure.core.exceptions.ResourceNotFoundError exception if an Azure OpenAI
    connection

    does not exist.

    Raises ~azure.core.exceptions.ModuleNotFoundError exception if the *openai* package

    is not installed.'
  signature: 'get_azure_openai_client(*, api_version: str | None = None, **kwargs)
    -> AzureOpenAI'
  keywordOnlyParameters:
  - name: api_version
    description: 'The Azure OpenAI api-version to use when creating the client. Optional.

      See "Data plane - Inference" row in the table at

      [https://learn.microsoft.com/azure/ai-services/openai/reference#api-specs](https://learn.microsoft.com/azure/ai-services/openai/reference#api-specs).
      If this keyword

      is not specified, you must set the environment variable *OPENAI_API_VERSION*
      instead.'
    types:
    - <xref:str>
  return:
    description: An authenticated AzureOpenAI client
    types:
    - <xref:openai.AzureOpenAI>
  exceptions:
  - type: azure.core.exceptions.ResourceNotFoundError
  - type: azure.core.exceptions.ModuleNotFoundError
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.projects.operations.InferenceOperations.get_chat_completions_client
  name: get_chat_completions_client
  summary: 'Get an authenticated ChatCompletionsClient (from the package azure-ai-inference)
    for the default

    Azure AI Services connected resource. At least one AI model that supports chat
    completions must be deployed

    in this resource. The package *azure-ai-inference* must be installed prior to
    calling this method.

    Raises ~azure.core.exceptions.ResourceNotFoundError exception if an Azure AI Services
    connection

    does not exist.

    Raises ~azure.core.exceptions.ModuleNotFoundError exception if the *azure-ai-inference*
    package

    is not installed.'
  signature: get_chat_completions_client(**kwargs) -> ChatCompletionsClient
  return:
    description: An authenticated chat completions client, or *None* if no Azure AI
      Services connection is found.
    types:
    - <xref:azure.ai.inference.models.ChatCompletionsClient>
  exceptions:
  - type: azure.core.exceptions.ResourceNotFoundError
  - type: azure.core.exceptions.ModuleNotFoundError
  - type: azure.core.exceptions.HttpResponseError
- uid: azure.ai.projects.operations.InferenceOperations.get_embeddings_client
  name: get_embeddings_client
  summary: 'Get an authenticated EmbeddingsClient (from the package azure-ai-inference)
    for the default

    Azure AI Services connected resource. At least one AI model that supports text
    embeddings must be deployed

    in this resource. The package *azure-ai-inference* must be installed prior to
    calling this method.

    Raises ~azure.core.exceptions.ResourceNotFoundError exception if an Azure AI Services
    connection

    does not exist.

    Raises ~azure.core.exceptions.ModuleNotFoundError exception if the *azure-ai-inference*
    package

    is not installed.'
  signature: get_embeddings_client(**kwargs) -> EmbeddingsClient
  return:
    description: An authenticated chat completions client
    types:
    - <xref:azure.ai.inference.models.EmbeddingsClient>
  exceptions:
  - type: azure.core.exceptions.ResourceNotFoundError
  - type: azure.core.exceptions.ModuleNotFoundError
  - type: azure.core.exceptions.HttpResponseError
